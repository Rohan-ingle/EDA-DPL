{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import googleapiclient.discovery\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "api_service_name = \"youtube\"\n",
    "api_version = \"v3\"\n",
    "DEVELOPER_KEY = \"AIzaSyDrO-T21_wPDt6bTUAYq8JVcay9rXuQ4Ro\"\n",
    "\n",
    "youtube = googleapiclient.discovery.build(\n",
    "    api_service_name, api_version, developerKey=DEVELOPER_KEY)\n",
    "\n",
    "comments = []\n",
    "\n",
    "def scrape(api_service_name, api_version, DEVELOPER_KEY, youtube, comments, next_page_token=None, count=0):\n",
    "    while True:\n",
    "        request = youtube.commentThreads().list(\n",
    "            part=\"snippet\",\n",
    "            videoId=\"PZH3H6hLOYk\",\n",
    "            maxResults=100,\n",
    "            pageToken=next_page_token\n",
    "        )\n",
    "        response = request.execute()\n",
    "\n",
    "        for item in response['items']:\n",
    "            comment = item['snippet']['topLevelComment']['snippet']\n",
    "            comments.append([\n",
    "                comment['textDisplay']\n",
    "            ])\n",
    "        next_page_token = response.get('nextPageToken')\n",
    "        count += 1\n",
    "\n",
    "        if not next_page_token:\n",
    "            break\n",
    "\n",
    "        if count == 30:\n",
    "            break\n",
    "\n",
    "        print(count)\n",
    "        #time.sleep(5)\n",
    "\n",
    "    df = pd.DataFrame(comments, columns=['text'])\n",
    "\n",
    "scrape(api_service_name, api_version, DEVELOPER_KEY, youtube, comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(text):\n",
    "    analysis = TextBlob(text)\n",
    "    if analysis.sentiment.polarity == 0:\n",
    "        return 0\n",
    "    elif analysis.sentiment.polarity > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "def get_sentiment_with_vader(text):\n",
    "    # Initialize the VADER sentiment analyzer\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "    # Get sentiment scores\n",
    "    sentiment_scores = sid.polarity_scores(text)\n",
    "\n",
    "    # Determine sentiment based on compound score\n",
    "    compound_score = sentiment_scores['compound']\n",
    "\n",
    "    # if compound_score >= 0.05:\n",
    "    #     return 1  # Positive sentiment\n",
    "    # elif compound_score <= -0.05:\n",
    "    #     return -1  # Negative sentiment\n",
    "    # else:\n",
    "    #     return 0  # Neutral sentiment\n",
    "    return compound_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import words\n",
    "\n",
    "# nltk.download('words')\n",
    "# nltk.download('punkt')\n",
    "\n",
    "english_words = set(words.words())\n",
    "\n",
    "def clean_text(text):\n",
    "\n",
    "    text = str(text)\n",
    "    blacklist = ['<br','_', '@','*','/', 'http', 'http:', 'bit.ly','</a>','<a>','href=']\n",
    "    \n",
    "    for word in blacklist:\n",
    "        text = text.replace(word, '')\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    words = nltk.word_tokenize(text)\n",
    "    \n",
    "    english_words_only = [word for word in words if word in english_words]\n",
    "    \n",
    "    cleaned_text = ' '.join(english_words_only)\n",
    "    \n",
    "    return cleaned_text\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "profane_words = []\n",
    "\n",
    "def filter_profanity(text):\n",
    "    pattern = r\"\\b(\" + \"|\".join(map(re.escape, profane_words)) + r\")\\b\"\n",
    "\n",
    "    filtered_text = re.sub(pattern, \"****\", text, flags=re.IGNORECASE)\n",
    "\n",
    "    return filtered_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(clean_text)\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['text'] != ' ']\n",
    "df = df[df['text'] != '']\n",
    "df = df[df['text'].str.len() != 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_sentiment(x):\n",
    "    if x > 0:\n",
    "        return 1\n",
    "    elif x < 0:\n",
    "        return -1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['sentiment'] = df['text'].apply(get_sentiment)\n",
    "df['sentiment'] = df['text'].apply(get_sentiment_with_vader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['sentiment'] =df['sentiment'].apply(replace_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text                                                      sentiment\n",
       "finally                                                    0           1478\n",
       "speed                                                      0            602\n",
       "first                                                      0            479\n",
       "w speed                                                    0            452\n",
       "hi                                                         0            334\n",
       "                                                                       ... \n",
       "i hope you like it subscribe if you did and if you don t   1              1\n",
       "i hope you knew its due                                    1              1\n",
       "i hope you have an amazing day                             1              1\n",
       "i hope you have a nice time                                1              1\n",
       "zoom is the bigger weakness of                            -1              1\n",
       "Name: count, Length: 140854, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text         0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1= pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68676"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['sentiment'] == 1.0]['sentiment'].value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69286"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['sentiment'] == 0.0]['sentiment'].value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27486"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['sentiment'] == -1.0]['sentiment'].value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df['sentiment'] = df[df['sentiment'] == 1.0]\n",
    "\n",
    "\n",
    "df1 = df1.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.sample(frac=1.0, random_state=42)\n",
    "\n",
    "df1 = df1.reset_index(drop=True)\n",
    "\n",
    "df1.to_csv('cleaned_positive_comments.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
